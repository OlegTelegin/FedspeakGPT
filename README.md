# FedspeakGPT
This collection of codes contributes to a broader project that utilizes GPT models to analyze Fedspeak. I plan to update the repository soon with the initial draft and all associated code and data. Currently, the repository serves to showcase code samples for RA applications. Briefly, the paper's main idea is that instead of using GPT to extract sentiment from messages in a naive way (prompt asking for the sentiment score), we can use embeddings as a much more accurate representation of how the model treats the text at hand. However, to use these embeddings effectively, we require a coordinate system that enables us to compute the sentiment. The FOMC Transcripts serve as an excellent case study for our methodology. For these Transcripts, the Fed staff's discussions in Tealbook B about draft Alternatives provide a naturally established coordinate system that facilitates our analysis.

Consider a thought experiment to illustrate the benefits of our approach. Imagine two different FOMC meetings. In the first, the options of -0.25, 0, and +0.25 are being considered, with varying views among Committee members. In the second meeting, the sole topic is to keep the rate unchanged, with members deliberating on nuanced aspects of a future statement. Relying solely on sentiment prompts would not allow for an adaptable approach between these distinct scenarios, likely diminishing the accuracy of sentiment analysis for the second one. However, we can discern the nuanced hawkish and dovish perspectives specific to each meeting by utilizing detailed discussions from Tealbook B - not just the draft alternatives but the entire discourse.

Currently, the repository contains .py scripts and a Shell script that summarizes and describes them. They tackle extracting text relevant to each of the Alternatives prepared by the Fed staff in Bluebooks/Tealbooks. These scripts are tailored to handle complex scenarios where the text may include graphs, tables, footnotes, and analytical boxes (insets). The scripts address situations where multiple Alternatives are mentioned in one sentence. They also detect when Alternatives are not the main focus but are merely referenced for comparative purposes, as well as identifying when the discussion of an Alternative concludes, even if the ending does not explicitly mention the Alternative. These issues are adeptly managed using the Python + GPT API. I will shortly enrich the repository with the projectâ€™s first draft and all the associated code and data. Should you need to review a single file, I recommend selecting gen mentions.py.

